---
title: "High Dimensional Data Analysis - Group Assignment 18"
author: "Group 18"
date: "08/09/2021"
output:
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 1
    toc_float:
      collapsed: false
    number_sections: false
    code_folding: show
    theme: readable
---

```{r setup, include=FALSE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      error = FALSE, 
                      fig.align = "center")
library(tidyverse)
library(dplyr)
library(visdat)
library(splitstackshape)
library(lubridate)
library(patchwork)
library(tidyverse)
library(dplyr)
library(kableExtra)
library(FactoMineR)
library(factoextra)
library(patchwork)
library(corrplot)
library(ggrepel)
bankruptcy <- read_rds(here::here("data/Bankruptcy.rds"))
```


\pagebreak

# Introduction

The UCLA-LoPucki Bankruptcy Research Database (BRD) is a UCLA School of Law data gathering, data linking, and data distribution initiative. The goal of the BRD is to encourage bankruptcy research by making bankruptcy data available to academic investigators worldwide. All of the data was gathered when the companies declared bankruptcy. In this study, we will use a variety of high-dimensional analysis approaches like Multidimesnionla Scaling, Principle Component Analysis and Clustering to extract useful insights from the data.


```{r, out.width=450}
knitr::include_graphics("data/bank.jpg")
```

\pagebreak

# Acknowledgement

Our sincere gratitude goes out to Ruben Loaiza-Maya and the our tutor Ari Handayani for their guidance and support. Our heartfelt thanks go to Ruben Loaiza-Maya and our instructor Ari Handayani for their advice and assistance. Their culminating efforts have placed us in a situation where we can produce this report collectively while showcasing our competence to employ diverse solutions that can be used with high dimensional data.


\pagebreak

# Data Description 

This report is based on data from US businesses that declared bankruptcy between 1980 and 2000. The information is coming from the UCLA-LoPucki Brankruptcy Research Database. Let's take a closer look at these variables and what they mean. Let's go further into the dataset to see if we can find any examples of data cleaning or wrangling.


The dataset has 436 observations and 7 variables with their description explained below.

- Name: Name of the firm
- Assets: Total assets (in millions of dollars)
- CityFiled: City where filing took place
- CPI U.S CPI at the time of filing
- DaysIn: Length of bankruptcy process
- DENYOther: CityFiled, categorized as Wilmington (DE), New York (NY) or all other cities (OT)
- Ebit: Earnings (operating income) at time of filing (in millions of dollars)
- Employees: Number of employees before bankruptcy
- EmplUnion: Number of union employees before bankruptcy
- FilingRate: Total number of other bankrupcy filings in the year of this filing
- FirmEnd: Short description of the event that ended the firmâ€™s existence
- GDP: Gross Domestic Product for the Quarter in which the case was filed
- HeadCityPop: The population of the firms headquarters city
- HeadCourtCityToDE: The distance in miles from the firms headquarters city to the city in which
the case was filed
- HeadStAtFiling: The state in which firms headquarters is located
- Liab: Total amount of money owed (in millions of dollars)
- MonthFiled: Categorical variable where numbers from 1 to 12 correspond to months from Jan to Dec
- PrimeFiling: Prime rate of interest on the bankruptcy filing date
- Sales: Sales before bankruptcy (in dollars)
- SICMajGroup: Standard industrial clasification code
- YearFiled: Year bankruptcy was filed


```{r}
bankruptcy <- bankruptcy %>%
  mutate(FirmEnd = ifelse(FirmEnd == "", 
                          NA, 
                          FirmEnd))

bankruptcy <- bankruptcy %>%
  separate(SICMajGroup, 
           into = c("SIC", "SICMajGroup"), 
           sep = "\\s", 
           extra = "merge") %>%
  mutate(SIC = as.factor(SIC))

bankruptcy %>% group_by(SIC) %>%
  summarise(median = median(DaysIn, na.rm = TRUE)) %>% 
    dplyr::filter(SIC %in% c(20, 53))

bankruptcy <- bankruptcy %>%
  mutate(DaysIn = ifelse(Name == "Hunt International Resources Corp.", 305,
                                    ifelse(Name == "AP Industries, Inc.", 121,
                                           ifelse(Name == "Daisy Systems Corp.", 1944,
                                                  ifelse(Name == "McCrory Corp.", 683, DaysIn)))))

bankruptcy <- bankruptcy %>%
  mutate(HeadCourtCityToDE = ifelse(Name == "Divi Hotels, N.V.", 1126,
                                    ifelse(Name == "Loewen Group, Inc.", 2942,
                                           ifelse(Name == "Philip Services Corp. (1999)", 1234,
                                                  HeadCourtCityToDE))))

bankruptcy <- bankruptcy %>%
  mutate(Employees = ifelse(Name == "County Seat, Inc.", 5180, Employees))

bankruptcy <- bankruptcy %>%
  mutate(Sales = ifelse(Name == "County Seat, Inc.", 1645170944, Sales))

bank_data_op1 <- bankruptcy %>%
  filter(!is.na(Ebit) & !is.na(Liab))

data_clean <- bank_data_op1 %>%
  select(-FirmEnd, -EmplUnion) %>%
  mutate(DENYOther = as.factor(DENYOther),
         MonthFiled = as.factor(MonthFiled),
         YearFiled = as.factor(YearFiled))

```



# Princple Component Analysis

Now that we've seen how to input this high-dimensional data into Multidimensional scaling (MDS) to obtain a low (typically 2) dimensional representation. Let us now perform a Principal Component Analysis (PCA), which is a dimensionality-reduction method that is frequently used to reduce the dimensionality of large data sets by transforming a large set of variables into a smaller one that still contains the majority of the information in the large set.







































