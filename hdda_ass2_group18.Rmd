---
title: "Assignment 2 Report"
author: Aarathy Babu, Dewi Amaliah, Priya Dingorkar, Rahul Bharadwaj
output: 
  bookdown::pdf_document2:
    toc: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.show = 'hold',
                      out.width = "70%", fig.align = 'center')
library(tidyverse)
library(dplyr)
library(visdat)
library(splitstackshape)
library(lubridate)
library(MASS)
library(kableExtra)
library(FactoMineR)
library(factoextra)
library(patchwork)
library(ggrepel)
library(ggfortify)
library(mclust)

bankruptcy <- read_rds(here::here("data/Bankruptcy.rds"))
```


# Data Description

In this study, we will use a variety of high-dimensional analysis approaches like Multidimensional Scaling, Principle Component Analysis, and Clustering to extract useful insights from the data. This report is based on data from US businesses that declared bankruptcy between 1980 and 2000. The information is coming from the UCLA-LoPucki Brankruptcy Research Database. This datasets has 21 variables and 436 firms with their description explained below.

- Name: Name of the firm
- Assets: Total assets (in millions of dollars)
- CityFiled: City where filing took place
- CPI U.S CPI at the time of filing
- DaysIn: Length of bankruptcy process
- DENYOther: CityFiled, categorized as Wilmington (DE), New York (NY) or all other cities (OT)
- Ebit: Earnings (operating income) at time of filing (in millions of dollars)
- Employees: Number of employees before bankruptcy
- EmplUnion: Number of union employees before bankruptcy
- FilingRate: Total number of other bankrupcy filings in the year of this filing
- FirmEnd: Short description of the event that ended the firm’s existence
- GDP: Gross Domestic Product for the Quarter in which the case was filed
- HeadCityPop: The population of the firms headquarters city
- HeadCourtCityToDE: The distance in miles from the firms headquarters city to the city in which
the case was filed
- HeadStAtFiling: The state in which firms headquarters is located
- Liab: Total amount of money owed (in millions of dollars)
- MonthFiled: Categorical variable where numbers from 1 to 12 correspond to months from Jan to Dec
- PrimeFiling: Prime rate of interest on the bankruptcy filing date
- Sales: Sales before bankruptcy (in dollars)
- SICMajGroup: Standard industrial clasification code
- YearFiled: Year bankruptcy was filed


# Preliminary Data Analysis

Before carrying out further analysis of the data, let us conduct some preliminary data analysis. Throughout our strategy, we have tried to retain the data as much as possible while maintaining high data quality and credibility. 

From the summary shown below, we have 6 character variables and 15 numeric variables.

```{r prelim-skimr}
glimpse(bankruptcy)
```

It can be observed that there are quite a number of empty values present in `FirmEnd` which are essentially `NULL` values. Therefore, we have converted these into`NA` values. 

```{r prelim-firmend}
bankruptcy <- bankruptcy %>%
  mutate(FirmEnd = ifelse(FirmEnd == "", 
                          NA, 
                          FirmEnd))
```

The data credibility issues are checked by confirming if the `DaysIn`, `EmplUnion`, `Employees`, `HeadCourtCityToDE`,`MonthFiled`, `YearFiled` and `HeadCityPop` are non-negative values. There are observations where the `EmplUnion` values are more than `Employees` which was removed from the data and that certain companies have 1 `Employees` and 1 `EmplUnion` values as shown below, which is suspicious but since there is not any concrete evidence that these observations pose data credibility issues, these observations were not excluded for the analysis. 

```{r}
bankruptcy%>%
  filter(EmplUnion>=Employees)%>%
  dplyr::select(Name,Employees,EmplUnion) %>%
  kable(caption = "Credibility issues in Employees and EmplUnion")%>%
  kable_styling(latex_options = "hold_position")
bankruptcy <-  bankruptcy %>%
filter(Name != "Promus Companies Inc. (Harrahs Jazz Co. only)")
```


We have separated `SICMajGroup` into a new factor variable `SIC` and its meaning in the `SICMajGroup` so as to make it more identifiable without the lengthy name.

```{r prelim-sic}
bankruptcy <- bankruptcy %>%
  separate(SICMajGroup, 
           into = c("SIC", "SICMajGroup"), 
           sep = "\\s", 
           extra = "merge") %>%
  mutate(SIC = as.factor(SIC))
```

The missing values in the data has been visualized as shown in figure \@ref(fig:prelim-vismiss). 

It can be observed that `FirmEnd` has the highest number of missing values, followed by `EmplUnion`. The strategy employed is to remove the variables `FirmEnd` and `EmplUnion`. As the variable `FirmEnd` depicts the description of the end of Firm's existence. It doesn't provide significant value to the analysis and it can be excluded. Similarly `EmplUnion` is removed due to the fact that `Employees` and `EmplUnion` are closely related and `EmplUnion` is be a subset of `Employees`. Therefore, removing `EmplUnion` which has too many missing values would not affect our analysis significantly. 

```{r prelim-vismiss, fig.cap="Overview of missing values in the data"}
vis_dat(bankruptcy)+
  ggtitle("Overview of data with missing values")
bankruptcy<- bankruptcy%>%
  dplyr::select(-FirmEnd,-EmplUnion)
```

The missing values of `DaysIn` in 4 companies were encoded based on the publicly available data and imputation. Values were encoded for **AP Industries** and **Daisy Systems Corp.** (See Appendix for more information). However, the data for **Hunt International Resources Corp.** and **McCrory Corp.** was not available, therefore we have imputed the variable, based on median of the `DaysIn` in the industry classification they belong to.

```{r prelim-daysin}
na_daysin <- filter(bankruptcy, is.na(DaysIn))
na_daysin%>%
  dplyr::select(c(Name,DaysIn) )%>%
  kableExtra::kable(caption = "Firms with missing values in DaysIn")%>%
  kable_styling(latex_options = "hold_position") %>%
  kableExtra::kable_paper()
```

```{r}
median_daysin<- bankruptcy %>% group_by(SIC) %>%
  summarise(median = median(DaysIn, na.rm = TRUE)) %>% 
    dplyr::filter(SIC %in% c(20, 53))
```


```{r prelim-daysinimpute}
bankruptcy <- bankruptcy %>%
  mutate(DaysIn = ifelse(Name == "Hunt International Resources Corp.", 305,
                                    ifelse(Name == "AP Industries, Inc.", 121,
                                           ifelse(Name == "Daisy Systems Corp.", 1944,
                                                  ifelse(Name == "McCrory Corp.", 683, DaysIn)))))
summary(bankruptcy$DaysIn)
```

The summary statistics of the variable after imputation, suggests no suspicious outliers or anomalies as the bankruptcy can be a lengthy ordeal. 

The missing values in `HeadCourtCityToDE` shown in the table below are imputed using the values in `CityFiled`, `DENYOther`, and `HeadStAtFiling`. Considering the publicly available data on headquarter address and the `CityFiled`, the distances between these cities were found and imputed into the data accordingly (see Appendix).
 
```{r prelim-headquart}
na_distance <- bankruptcy %>%
  filter(is.na(HeadCourtCityToDE))
na_distance%>%
  dplyr::select(Name,HeadCourtCityToDE,CityFiled,DENYOther,HeadStAtFiling)%>%
  kableExtra::kable(caption = "Missing values in `HeadCourtCityToDE`")%>%
  kable_styling(latex_options = "hold_position") %>%
  kableExtra::kable_paper()
```

```{r}
bankruptcy <- bankruptcy %>%
  mutate(HeadCourtCityToDE = ifelse(Name == "Divi Hotels, N.V.", 1126,
                                    ifelse(Name == "Loewen Group, Inc.", 2942,
                                           ifelse(Name == "Philip Services Corp. (1999)", 1234,
                                                  HeadCourtCityToDE))))
summary(bankruptcy$HeadCourtCityToDE)
bankruptcy%>%
  filter(HeadCourtCityToDE==1)%>%
  dplyr::select(Name,HeadCourtCityToDE,CityFiled,DENYOther,HeadStAtFiling)%>%
  kableExtra::kable(caption = "Firms with headquarters and the city filed in the same state")%>%
  kable_styling(latex_options = "hold_position") %>%
  kableExtra::kable_paper()
```


Exploring the summary statistics, it was observed that the minimum distance is 1, when inspected the state of headquarters and the city filed is in the same state. Therefore it does not pose a data credibility issue. 

With regards to the `Employees` variable, it was observed that there is a single observation that is missing data on its employees. Under closer examination of the `Sales` Variable, we observed that it was the same firm that had missing data on `Sales` as well. On closer inspection of this firm, the presence of missing values on the variable `Ebit` was also found, therefore we remove this observation considering the fact that this single observation has missing values of these three variables.

```{r}
na_sales <- filter(bankruptcy, is.na(Sales))
na_employees <- filter(bankruptcy, is.na(Employees))
options(scipen = 999)
bankruptcy%>%
  filter(Name=="County Seat, Inc.")%>%
  dplyr::select(Name,Sales,Employees,Ebit) %>%
  kable(caption = "Firms with missing values in Sales, Employees, and Ebit") %>%
  kable_styling(latex_options = "hold_position") %>%
  kable_paper()
bankruptcy<- bankruptcy%>%
  filter(!is.na(Sales))
```


The missing values in `Liab` and `Ebit` was treated by dropping the missing observations, as the missing values in each of the variables were below 10% and out of the 39 rows where either one of the two variables were missing, 8 of the observations have missing values on both `Liab` and `Ebit`. We believe it is more reasonable to drop the missing values than impute them as imputation could mislead the analysis.  

```{r}
all_liab_ebit_missing<- bankruptcy %>%
  filter(is.na(Ebit) |is.na(Liab))
bank_data_op1 <- bankruptcy %>%
  filter(!is.na(Ebit) & !is.na(Liab))
data_label <- bank_data_op1%>%
  filter(Ebit==max(Ebit)|Liab==max(Liab)|Sales==max(Sales)|Assets==max(Assets))%>%
  dplyr::select(Name,Ebit,Liab,Sales,Assets)
```


`DENYOther`, `MonthFiled` and `YearFiled` ought to be factor as mentioned in the data description therefore are converted to factor from numeric variables as shown in figure \@ref(fig:cleandata)

```{r cleandata, fig.cap="Overview of Cleaned Data"}
data_clean <- bank_data_op1 %>%
  mutate(DENYOther = as.factor(DENYOther),
         MonthFiled = as.factor(MonthFiled),
         YearFiled = as.factor(YearFiled))
row.names(data_clean) <- data_clean$Name
vis_dat(data_clean)
```

The data was then checked for outliers, even though we haven't found suspicious outliers in majority of the variables (see Appendix), outliers were found in `Ebit`, `Liab` , `Assets` and `Sales` as shown below in figure \@ref(fig:prelimoutlier-1) and \@ref(fig:prelimoutlier-2). Interestingly, these values belong to a single firm called **Texaco Inc.**. This will be discussed further in the sections below.

```{r prelimoutlier-1, fig.cap="Presence of Outliers in Sales and Assests"}
p3 <- data_clean%>%
  ggplot()+
  geom_histogram(aes(x=Sales),fill="blue",alpha=0.7)+
    geom_text(data=data_label,aes(x=Sales,y=50,label=Name),
    hjust = 0.7, size = 4)+
  theme_bw()+
  ggtitle("Sales")+
  ylab("Count")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p1<- data_clean%>%
  ggplot()+
  geom_histogram(aes(x=Ebit),fill="blue",alpha=0.7)+
  geom_text(data=data_label,aes(x=Ebit,y=50,label=Name),
    hjust = 0.7, size = 4)+
  theme_bw()+
  ggtitle("Ebit")+
  ylab("Count")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p2 <- data_clean%>%
  ggplot()+
  geom_histogram(aes(x=Liab),fill="blue",alpha=0.7)+
  geom_text(data=data_label,aes(x=Liab,y=50,label=Name),
    hjust = 0.7, size = 4)+
  theme_bw()+
  ggtitle("Liab")+
  ylab("Count")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p4 <- data_clean%>%
  ggplot()+
  geom_histogram(aes(x=Assets),fill="blue",alpha=0.7)+
  geom_text(data=data_label,aes(x=Assets,y=50,label=Name),
    hjust = 0.7, size = 4)+
  theme_bw()+
  ggtitle("Assets")+
  ylab("Count")+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
p3+p4
```


```{r prelimoutlier-2,fig.cap="Presence of Outliers in Ebit and Liab"}
p1+p2
```

In order to gain insights from the data, we have further explored it. Below shown is a correlation plot. It is clear from the plot that `HeadCityPop`and `HeadCourtCityToDE` have no correlation with any of the other variables. Therefore, we omit these two variables from further analysis. 

```{r, fig.cap= "Correlation plot of numeric variables in the cleaned data", out.width="70%"}
A = cor(data_clean%>%select_if(is.numeric))

cex.before <- par("cex")
par(cex = 0.7)

corrplot::corrplot(A, method = 'number',
                   tl.col = "black", 
                   tl.cex = 1/par("cex"),
                   cl.cex = 1/par("cex"), 
                   addCoefasPercent = TRUE)

par(cex = cex.before)


data_clean<- data_clean%>%
  dplyr::select(-HeadCityPop,-HeadCourtCityToDE)
```

# Multidimensional Scaling (MDS)

MDS is a statistical method to represent multidimensional data into lower-dimensional (2D) data. Thus, MDS is relevant to represent bankruptcy data in two-dimensional visualisation. This method uses distance to do the job. Hence, we limit the MDS only to incorporate numerical variables so that we can use Euclidean distance or is known as classical MDS. We will also only incorporate numerical variables directly related to bankruptcy. Those variables are: `Assest`, `DaysIn`, `Employees`, `CPI`, `Ebit`, `Liab`, `FillingRate`, `GDP`, `PrimeFilling`, and `Sales`. These variables has different unit of measurements, hence we standardise it.

## Classical MDS

```{r}
dd <- data_clean %>% 
  dplyr::select(c(Assets, DaysIn, Employees, CPI, Ebit, Liab, FilingRate, GDP, PrimeFiling, Sales)) %>%
  #select_if(is.numeric) %>%
  scale %>% dist()

#rownames(clean_data) -> attributes(dd)$Labels


cmds <- cmdscale(dd,eig = T)

df <- cmds$points %>%
  as.data.frame()

df_join <- cbind(df, data_clean) %>%
  mutate(Names = abbreviate(Name)) 
```


```{r cmds-plot, fig.cap="Classical MDS solution for bankruptcy data. The x and y-axis represent the new variables as the result of MDS. Some outliers observed in thedata"}
ggplot(df_join,
             aes(x=V1,
                 y=V2,
                 label= Names)) + 
  geom_text(size=2) +
  theme_bw()
```

Figure \@ref(fig:cmds-plot) conveys that Texaco Inc (Tin.), Baldwin-United Corporation (B-UC), Federated Department Stores, Inc. (FDSI), LTV Corp. (1986) (LTCV.(1) are potential outliers. On closer inspection of the data, we find that these firms have the largest assets. Moreover, Texaco Inc. also has high operating income, sales, and liability.  

As mentioned previously, the aim of MDS is to visualise the firms in 2D scatter plot. However, this objective will be less clearly achieved in Figure \@ref(fig:cmds-plot) since too many observations overlapped each other. Hence, we decide to exclude Texaco Inc. and re-conduct classical MDS. This gives us a clearer visualisation as follows:


```{r}
exclude_texaco <- data_clean %>%
  filter(Name != "Texaco Inc.")

dd_excl <- exclude_texaco %>% 
  dplyr::select(c(Assets, DaysIn, Employees, CPI, Ebit, Liab, FilingRate, GDP, PrimeFiling, Sales)) %>%
  #select_if(is.numeric) %>%
  scale %>% dist()

#rownames(clean_data) -> attributes(dd)$Labels


cmds_excl <- cmdscale(dd_excl,eig = T)

df_excl <- cmds_excl$points %>%
  as.data.frame()

df_join_excl <- cbind(df_excl, exclude_texaco) %>%
  mutate(Names = abbreviate(Name)) %>%
  mutate(SIC_collaps = fct_collapse(SICMajGroup, `Crops` = "Crops",
                                    `Mining, Oil & Gas Extraction` = c("Metal Mining", "Coal Mining",
                                                                       "Oil And Gas Extraction"),
                                    `Construction` = c("Building Construction General Contractors And Operative Builders",
                                                       "Heavy Construction Other Than Building Construction Contractors",
                                                       "Construction Special Trade Contractors"),
                                    `Manufacture` = c("Food and Kindred Products",
                                                      "Textile Mill Products",
                                                      "Apparel And Other Finished Products Made From Fabrics And Similar Materi",
                                                      "Lumber And Wood Products, Except Furniture",
                                                      "Furniture And Fixtures",
                                                      "Paper and Allied Products",
                                                      "Printing, Publishing, And Allied Industries",
                                                      "Chemicals and Allied Products",
                                                      "Petroleum Refining And Related Industries",
                                                      "Rubber and Miscellaneous Plastics Products",
                                                      "Stone, Clay, Glass, And Concrete Products",
                                                      "Primary Metal Industries",
                                                      "Fabricated Metal Products, Except Machinery and Transportation Equipment",
                                                      "Industrial and Commercial Machinery and Computer Equipment",
                                                      "Electronic And Other Electrical Equipment And Components",
                                                      "Transportation Equipment",
                                                      "Measuring, Analyzing and Controlling Instruments; Photographic, Medical",
                                                      "Miscellaneous Manufacturing Industries"),
                                    `Transportation & Warehouse` = c("Local And Suburban Transit And Interurban Highway Passenger Transportati",
                                                                     "Motor Freight Transportation And Warehousing",
                                                                     "Water Transportation",
                                                                     "Transportation By Air"),
                                    `Communications` = "Communications",
                                    `Services` = c("Electric, Gas, And Sanitary Services",
                                                   "Personal Services",
                                                   "Business Services",
                                                   "Automotive Repair, Services, and Parking",
                                                   "Miscellaneous Repair Services",
                                                   "Motion Pictures",
                                                   "Amusement And Recreation Services",
                                                   "Health Services",
                                                   "Social Services",
                                                   "Engineering, Accounting, Research, Management, and Related Services"),
                                    `Wholesale & Retail` = c("Wholesale Trade-durable Goods",
                                                             "Wholesale Trade-non-durable Goods",
                                                             "Building Materials, Hardware, Garden Supply, And Mobile Home Dealers",
                                                             "General Merchandise Stores",
                                                             "Food Stores",
                                                             "Apparel And Accessory Stores",
                                                             "Home Furniture, Furnishings, and Equipment Stores",
                                                             "Eating and Drinking Places",
                                                             "Miscellaneous Retail"),
                                    `Finance` = c("Depository Institutions",
                                                  "Non-depository Credit Institutions",
                                                  "Insurance Carriers"),
                                    `Real Estate` = c("Real Estate",
                                                      "Holding And Other Investment Offices",
                                                      "Hotels, Rooming Houses, Camps, and Other Lodging Places")))
```


```{r cmds-plot-excl, fig.cap="Classical MDS solution for bankruptcy data after excluding Texaco Inc. The x and y-axis represent the new variables as the result of MDS. We get a clearer visualisation compared to the previous MDS result"}
ggplot(df_join_excl,
             aes(x=V1,
                 y=V2,
                 label= Names)) + 
  geom_text(size=2) +
  theme_bw()
```


Figure \@ref(fig:cmds-plot-excl) suggests that the visual representation of the rest firms other than Texaco, Inc. remains the same. B-UC, LTCV.(1, and FDSI are still far apart from other firms. It implies that our MDS is pretty robust. However, since it gives a clearer visualisation, we will use the data without Texaco, Inc. in the rest of MDS analysis. It also implies that most firms that filed for bankruptcy have similar characteristics since they tend to be plotted near or even overlapped with each other. We can also see that some firms are spread out. It means that these firms have different profile. 

## Goodness of Fit

In this part, we inspect the MDS’s Goodness of Fit. If two GoF values are equal, which is the ideal condition if we use Eucledean distance, then we can conclude that the strain is minimised and the solution is optimal. Here is the GoFs of the MDS:

```{r}
str(cmds_excl$GOF)
```

We find that the $GoF_1$ and $GoF_2$ are equal. Hence, our MDS is optimal. We also find that all the eigenvalues are positive (see Appendix). 

## Comparison with non-Classical MDS

Next, we compare the classical MDS with non-classical MDS (Sammon mapping). The stress function could be used to indicate the accuracy of representation. The lower, the better the accuracy. 

```{r}
smds<-sammon(dd_excl)
smds$stress
```


We find that the stress is relatively low (0.121), thus non-classical MDS also produce fairly accurate representation of the bankruptcy data. Moreover, the plot (see Appendix) also produce relatively similar result when compared with the classical MDS. Hence, we can conclude that the result is fairly robust with the change of methodology. 

## Visualisation with Categorical Variable

This section will show the MDS solution by also take the categorical variables into account. Too keep the report concise, we displaye some categorical features in the Appendix and only display interesting finding in this subsection. 

```{r cmds-year, fig.cap = "Classical MDS solution plotted by year when the bankruptcy filed."}
ggplot(df_join_excl,
             aes(x=V1,
                 y=V2,
                 label= Names,
                 color = YearFiled)) + 
  geom_text(size=3) +
  theme_bw() +
  theme(legend.position = "bottom")
```

The classical MDS solution plotted by year as shown in Figure \@ref(fig:cmds-year) shows that there is pattern regarding the year. Firms who filed for bankruptcy in the same year tend to be similar each other. This could be because in the same year, CPI, filing rate, and prime interest are pretty similar. This is an interesting finding since we could infer that macroeconomic ,i.e, market condition could profile firms who filed for bankruptcy. 


# Principal Component Analysis (PCA)

In this section, we perform PCA, a dimension reduction method by transforming a large set of variables into a smaller one while retaining the variance of the data. We display the PCA without the Texaco Inc. as done in MDS (see Appendix for PCA including the outlier observation). We standardized our variables to ensure the results are not sensitive to the units of measurement. Thus, giving us more accurate analysis.

## The PCA

```{r}
nooutlier <- data_clean %>%
    mutate(abb=abbreviate(Name))
nooutlier <- nooutlier%>%
  dplyr::filter(abb!="TIn.")
nooutlier%>%
  select_if(is.numeric)%>%
  prcomp(scale. = TRUE)->pca_no_out
summary(pca_no_out)
```

From the output above we learn:

- Proportion of variance explained by the first four PCs together is now 67.99%.
- Proportion of variance explained by the first and second PC alone is 26.41% and 22.24%, respectively.
- Kaiser's rule, which choose the PC's whose variance and standard deviation greater than 1, suggests to choose 4 PCs. However, we will inspect it further using the scree plot. 


```{r screeplot, fig.cap="Screeplot of PCA on bankruptcy data"}
screeplot(pca_no_out,type="lines") 
```

- Interestingly the scree plot and the Kaiser's rule do not agree with each other. However, we refer to scree plot since it is more distinguishable to show the elbow structure.  

- The scree plot suggests to include 3 PCs which explain 68.75% variations of the data. However, we cannot visualise it in biplot, so we plot the first two PC's as they explain 57.87% of variation in our data. 

```{r biplotout, fig.cap="PCA Biplot without Outliers"}
rownames(pca_no_out$x)<-pull(nooutlier,abb)
autoplot(pca_no_out,label = TRUE, label.size = 2.5,
         loadings = TRUE, loadings.colour = 'blue',
         loadings.label = TRUE, loadings.label.size = 4.5) +
  labs(title = "Biplot on Bankruptcy without Outliers") +
  theme_bw()
```


From figure \@ref(fig:biplotout), we can infer the following:

- The firms are spread out in different direction showing different properties with the surrounding variables. For instance, two companies that show similar characteristics are FDSI and LDVC and the ones that show very dissimilar characteristics to each other are FDSI and DESL. 
- The further away these vectors or variables are from a PC origin, the more influence they have on that PC. For instance taking a closer a look at the left quadrant, we infer that CPI has more influence, followed by `GDP` and `FilingRate` whereas `Ebit` has the least influence among all the variables.
- `Employees` and `GDP`/`CPI` shows an angle of almost 90°. Thus, there is no correlation between these variables.
- `PrimeFiling` is negatively correlated with `GDP`, `CPI`, and `FilingRate` since the angle is almost 180°.
- `CPI` and `GDP `are highly positively correlated. `Assets`, `Liab`, `Ebit`, and `Sales` are all also positively correlated as the angle between them is nearly zero.


```{r corrplot, fig.cap="PCA Correlation Plot"}
var <- get_pca_var(pca_no_out)
fviz_pca_var(pca_no_out, col.var = "black") +
  labs(title = "Correlation Plot") +
  theme_bw()
```

Figure \@ref(fig:corrplot) shows a clearer visuals of the angles between variables so that we can distinguish between the variables that are positively, negatively, or not correlated at all.

# Cluster Analysis

Clustering is the process of grouping the observations into categories or groups of observations based on their similarities. It helps us identify the commonalities and similar characteristics within the data which help us answer business questions.

In this case, we can validate if there are any similarities among the companies that are going bankrupt. This helps us understand the most possible reason for organisations going bankrupt and possibly help prevent the same in the future.

There are two main types of clustering namely, hierarchical and non-hierarchical clustering. Non-hierarchical clustering with the number of clusters known ex ante are useful if the number of clusters can be determined beforehand. We will mainly focus on Hierarchical clustering method.

### Hierarchical Clustering:

```{r clust, fig.cap= "Dendrogram with Ward's menthod and 3 clusters.", out.width="60%"}
clust_data <- data_clean %>% 
  ungroup %>% 
  dplyr::filter(Name != "Texaco Inc.") %>% 
  dplyr::select(c(Assets, CPI, DaysIn, Employees, 
                  Ebit, Liab, FilingRate, GDP, 
                  PrimeFiling, Sales)) %>%
  select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "ward.D2")
clust_data %>% plot(cex=.5)
clust_data %>% rect.hclust(k=3)
```

Ward D2 method gives the best clustering outcome with reasonable sized clusters so we compare all other clusters with this method (See Appendix for other methods).

Figure \@ref(fig:clust) shows that there is a big range of Height tolerance on y-axis for k = 3 with the next values at 34 and and 23 for k = 2 and k = 4, respectively (see Appendix for height with different *k*). Thus, we cluster the data into three clusters as it has the highest range which keeps our clustering stable.  

### Choosing the best method:

```{r}
data_clean %>% ungroup() %>% select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "ward.D2") %>% cutree(k = 10)-> memb_ten_w
data_clean %>% ungroup() %>% select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "average") %>% cutree(k = 10)-> memb_ten_al
data_clean %>% ungroup() %>% select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "centroid") %>% cutree(k = 10)-> memb_ten_cm
data_clean %>% ungroup() %>% select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "complete") %>% cutree(k = 10)-> memb_ten_cl
```

Average Method:
```{r}
adjustedRandIndex(memb_ten_w, memb_ten_al)
```

Centroid Method:
```{r}
adjustedRandIndex(memb_ten_w, memb_ten_cm)
```

Complete Method:
```{r}
adjustedRandIndex(memb_ten_w, memb_ten_cl)
```


The complete linkage method has the highest agreement with Ward D2 between the different types of clustering. If all the clustering methods give almost similar results, then we can safely say that the data has some evident observable patterns. If not, the data does not have any solid patterns to cluster it based on similarities. In our case, there is no solid evidence of clustering results from the different methods. Each method gives an almost new result. Thus we can say that from the given data it is hard to find patterns that are making the organizations go bankrupt. The closest method to Ward D2 is Complete Linkage method which is 44% similar to the Ward D2 method.


# Limitations

- We only use numerical data in the MDS analysis due to the complexity of incorporating non-numeric data. However, we tried to also display that categorical variable when visualising the MDS result. 
- The scree plot infer that our data was mostly explained by the the first three PCs. However, due to the limitations of biplot we have visualized our data using the first and the second PCs only. This mean they might be certain patterns in the data and to visualize third PCs we will further need to work on the structure of the data.
- Since our focus is on hierarchical clustering, it does not consider all possible clusters like in k-means clustering.

\pagebreak

# Appendix

## Data Cleaning 

**Imputation of variable `HeadCourtCityToDE`**

As per our research online, we came to the conclusion that the `HeadCourtCityToDE` for [Divi Hotels, N.V.](https://www.bloomberg.com/profile/company/DVH:US) is 1126 miles where as for [Loewen Group, Inc](https://www.sedar.com/DisplayProfile.do?lang=EN&issuerType=03&issuerNo=00001601) (British Columbia to Wilmington)  and [Philip Services Corp.](https://www.sedar.com/DisplayProfile.do?lang=EN&issuerType=03&issuerNo=00001613) (Ontario to Wilmington) is 2942 and 1234 miles respectively.

**Imputation of variable `DaysIn`**


  - `DaysIn` can be encoded equivalent to 121 days for [AP Industries, Inc.](https://casetext.com/case/in-re-ap-industries-inc?__cf_chl_jschl_tk__=pmd_0e9LcvX3fGC0nT5WJVBShbHDvK9GY2AMZnekCjslbN0-1631333530-0-gqNtZGzNAjujcnBszQd9) 

  - `DaysIn` can be encoded equivalent to 1944 days for [Daisy Systems Corp.](https://caselaw.findlaw.com/us-9th-circuit/1020075.html)  


**Dealing Missing Values in `Sales` and `Employees`** 

```{r}
na_sales%>%
  dplyr::select(Name,Sales) %>%
  kableExtra::kable(caption = "Missing values in Sales") %>%
  kable_styling(latex_options = "hold_position") %>%
  kableExtra::kable_paper()
```

```{r}
na_employees%>%
  dplyr::select(Name,Employees)%>%
  kableExtra::kable(caption = "Missing values in Employees")%>%
  kable_styling(latex_options = "hold_position") %>%
  kableExtra::kable_paper()
```
   
   
**Checking Outliers**

```{r}
out1 <- bankruptcy%>%
  ggplot(aes(x=DaysIn))+
  geom_histogram(fill="blue",alpha=0.7)+
  theme_bw()+
  ggtitle("DaysIn")+
  ylab("Count")
```

```{r prelim-headquarthisto, fig.cap="The figure indicates that there isnt any outliers in the variables DaysIn and HeadCourtCitytoDE"}
out2<- bankruptcy%>%
  ggplot(aes(x=HeadCourtCityToDE))+
  geom_histogram(fill="blue",alpha=0.7)+
  theme_bw()+
  ggtitle("HeadCourtCityToDE")+
  ylab("Count")
out1+out2
```

## MDS

**Eigenvalues of classical MDS**

```{r}
min(cmds_excl$eig)
```

Since the values has e-12, it is reciprocal to 2 with 12 trailing zeros. Hence, even though it looks negative, it is very close, even indistinguishable from zero.  That is why the value of $GoF_1$ and $GoF_2$ are equal. 

**MDS plot using Sammon mapping**

```{r sammon-plot, fig.cap="MDS solution using Sammon mapping"}
df_join_excl <-add_column(df_join_excl,Sammon1=smds$points[,1],
                     Sammon2=smds$points[,2])

ggplot(df_join_excl,aes(x=Sammon1,y=Sammon2, label=`Names`))+ geom_text(size=2) +
  theme_bw()
```

**Additional plots of MDS based on the city where the bankruptcy filed**

```{r cmds-city, fig.cap = "Classical MDS solution plotted by city where the bankruptcy filed."}
ggplot(df_join_excl,
             aes(x=V1,
                 y=V2,
                 label= Names,
                 color = DENYOther)) + 
  geom_text(size=3) +
  theme_bw() +
  theme(legend.position = "bottom") +
  guides(color=guide_legend(title="City"))
```

Figure \@ref(fig:cmds-city) shows no specific pattern of bankruptcy regarding the city where it is filed. The firms who similar to each other (as seen in the overlapped text) could filed for bankruptcy in different city. Besides, firms who are potentially outliers (B-UC, LTCV.(1, and FDSI) are not filed their bankruptcy in Delaware. 

**Additional plots of MDS based on industry**

Figure \@ref(fig:cmds-industry) shows the classical MDS solution by industry classification. Note that in the original data, there are 55 industry. This number is too big to be plotted, hence we collapse some industry which has the similar sector, for example manufacture, mining, construction, and finance. 

```{r cmds-industry, fig.cap = "Classical MDS solution plotted by industry."}
ggplot(df_join_excl,
             aes(x=V1,
                 y=V2,
                 label= Names,
                 color = SIC_collaps)) + 
  geom_text(size=3) +
  theme_bw() +
  theme(legend.position = "bottom") +
  guides(color=guide_legend(title="Industry")) +
  scale_colour_manual(values = c("red", "#884EA0", "#3498DB", "#16A085", "#F1C40F",
                                 "#2ECC71", "#EB984E", "pink", "magenta", "black"))
```

Figure \@ref(fig:cmds-industry) suggests that there is no clear specific pattern of the firm bankruptcy regarding the industry. Wholesale and retail firms is bit more spread out. Manufacture industry is also observed to be spread out everywhere and could be because this industry has many observations. Further, B-UC and SthmCrp. are observed to be relatively further apart from the other real estate firms since they have bigger assets.

## PCA 

**PCA performed on the complete data including outliers**

```{r}
data_clean%>%
  select_if(is.numeric)%>%
  prcomp(scale. = TRUE)->pca
```

```{r}
summary(pca)
```


- Using the `summary` function we can infer the following:
  + Proportion of variance explained by the first four PCs together is 73.28%
  + Proportion of variance explained by the first and second PC alone is 30.10% and 23.64% respectively
  + Using kaisers rule, we choose those PC's whose variance and standard deviation is greater than 1, in our bankruptcy data we will choose 4 PC's.


- Let us now plot use the scree plot to find the total number of PC's that best explain our data.

```{r plotscree, fig.cap="Scree Plot"}
screeplot(pca,type="lines")
```


- Using the scree plot we infer that our bankruptcy data is explained by the first three PC's. Also note this is different to kaisers rule.

- Let us now plot a biplot, that will help us infer intersting features about our data. A PCA biplot shows both PC scores of samples (dots) and loadings of variables(vectors).

```{r biplotbank, fig.cap="PCA Biplot"}
data_clean <- data_clean %>%
  mutate(abbreviation=abbreviate(Name))
rownames(pca$x)<-pull(data_clean,abbreviation)
autoplot(pca,label = TRUE, 
         label.size = 3.6,
         loadings = TRUE, 
         loadings.colour = 'blue',
         loadings.label = TRUE, 
         loadings.label.size = 4.5) +
  labs(title = "Biplot on Bankruptcy Dataset") +
  theme_bw()
```

## Cluster Analysis 

**The tolerance values for different number of clusters**
  + when k = 2 height is around 34
  + when k = 3 height is around 29
  + when k = 4 height is around 23
  + when k = 6 height is around 21
  + when k = 7 height is around 18

**Plots for Average, Complete, and Centroid**

```{r ave, fig.cap="Dendrogram with average method"}

clust_data_ave <- data_clean %>% 
  ungroup %>% 
  dplyr::filter(Name != "Texaco Inc.") %>% 
  dplyr::select(c(Assets, CPI, DaysIn, Employees, 
                  Ebit, Liab, FilingRate, GDP, 
                  PrimeFiling, Sales)) %>%
  select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "average")
clust_data_ave %>% plot(cex=.5)
clust_data_ave %>% rect.hclust(k=3)
```

```{r cmp, fig.cap="Dendrogram with complete method"}

clust_data_cmp <- data_clean %>% 
  ungroup %>% 
  dplyr::filter(Name != "Texaco Inc.") %>% 
  dplyr::select(c(Assets, CPI, DaysIn, Employees, 
                  Ebit, Liab, FilingRate, GDP, 
                  PrimeFiling, Sales)) %>%
  select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "complete")
clust_data_cmp %>% plot(cex=.5)
clust_data_cmp %>% rect.hclust(k=3)
```

```{r cnt, fig.cap="Dendrogram with centroid method"}

clust_data_cnt <- data_clean %>% 
  ungroup %>% 
  dplyr::filter(Name != "Texaco Inc.") %>% 
  dplyr::select(c(Assets, CPI, DaysIn, Employees, 
                  Ebit, Liab, FilingRate, GDP, 
                  PrimeFiling, Sales)) %>%
  select_if(is.numeric) %>%
  scale %>% dist() %>% hclust(method = "centroid")
clust_data_cnt %>% plot(cex=.5)
clust_data_cnt %>% rect.hclust(k=3)
```


# Acknowledgment

Our sincere gratitude goes out to Ruben Loaiza-Maya and the our tutor Ari Handayani for their guidance and support. Their culminating efforts have placed us in a situation where we can produce this report collectively while showcasing our competence to employ diverse solutions that can be used with high dimensional data. 

# References 

Loaiza-Maya, Ruben. (2021). Cluster Analysis. High Dimensional Data Analysis Lecture Notes. 

Loaiza-Maya, Ruben. (2021). Multidimensional Scaling. High Dimensional Data Analysis Lecture Notes.

Loaiza-Maya, Ruben. (2021). Principal Component Analysis. High Dimensional Data Analysis Lecture Notes.

# R Packages Used

Allaire JJ and Yihui Xie and Jonathan McPherson and Javier Luraschi and Kevin Ushey and Aron
  Atkins and Hadley Wickham and Joe Cheng and Winston Chang and Richard Iannone (2020).
  rmarkdown: Dynamic Documents for R. R package version 2.5. URL https://rmarkdown.rstudio.com.

Grolemund G., Hadley Wickham (2011). Dates and Times Made Easy with
  lubridate. Journal of Statistical Software, 40(3), 1-25. URL
  https://www.jstatsoft.org/v40/i03/.
  
Horikoshi M., Yuan Tang (2016). ggfortify: Data Visualization Tools for Statistical
  Analysis Results. https://CRAN.R-project.org/package=ggfortify
  
Kassambara A., Fabian Mundt (2020). factoextra: Extract and Visualize the Results of
  Multivariate Data Analyses. R package version 1.0.7.
  https://CRAN.R-project.org/package=factoextra

Le S., Julie Josse, Francois Husson (2008). FactoMineR: An R Package for Multivariate
  Analysis. Journal of Statistical Software, 25(1), 1-18. 10.18637/jss.v025.i01

Mahto A (2019). splitstackshape: Stack and Reshape Datasets After Splitting Concatenated
  Values. R package version 1.4.8. https://CRAN.R-project.org/package=splitstackshape

Pedersen T.L. (2020). patchwork: The Composer of Plots. R package version
  1.1.1. https://CRAN.R-project.org/package=patchwork

Scrucca L., Fop M., Murphy T. B. and Raftery A. E. (2016) mclust 5: clustering,
  classification and density estimation using Gaussian finite mixture models The R
  Journal 8/1, pp. 289-317

Slowikowski K (2021). ggrepel: Automatically Position Non-Overlapping Text
  Labels with 'ggplot2'. R package version 0.9.1.
  https://CRAN.R-project.org/package=ggrepel

Tierney N (2017). “visdat: Visualising Whole Data Frames.” _JOSS_, *2*(16), 355. doi:
10.21105/joss.00355 (URL: https://doi.org/10.21105/joss.00355), <URL:
http://dx.doi.org/10.21105/joss.00355>.

Venables, W. N. & Ripley, B. D. (2002) Modern Applied Statistics with S. Fourth Edition.
  Springer, New York. ISBN 0-387-95457-0
  
Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686,
  https://doi.org/10.21105/joss.01686
  
Wickham, Romain François, Lionel Henry and Kirill Müller (2021). dplyr: A Grammar of
  Data Manipulation. R package version 1.0.7. https://CRAN.R-project.org/package=dplyr

Xie, Y. (2021). knitr: A General-Purpose Package for Dynamic Report Generation
  in R. R package version 1.33.

Xie, Y. (2021). knitr: A General-Purpose Package for Dynamic Report Generation
  in R. R package version 1.33.

Zhu, Hao (2021). kableExtra: Construct Complex Table with 'kable' and Pipe Syntax.
  R package version 1.3.4. https://CRAN.R-project.org/package=kableExtra
